{"cells":[{"cell_type":"code","execution_count":1,"id":"acCvOhlLLLQ7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27847,"status":"ok","timestamp":1716912682812,"user":{"displayName":"model trainer","userId":"06698139684495762614"},"user_tz":-420},"id":"acCvOhlLLLQ7","outputId":"41c6dbab-9a48-401e-dee7-799bd95a10d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","id":"194806ab-bd64-40d2-92f7-d8d8c9067d02","metadata":{"id":"194806ab-bd64-40d2-92f7-d8d8c9067d02"},"source":["# Install Library"]},{"cell_type":"code","execution_count":17,"id":"b046eb44-bada-4831-be9a-149c3269c0ff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28724,"status":"ok","timestamp":1716912813895,"user":{"displayName":"model trainer","userId":"06698139684495762614"},"user_tz":-420},"id":"b046eb44-bada-4831-be9a-149c3269c0ff","outputId":"36eca2fd-9c5e-4bb4-cde5-4e2d10067552","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]}],"source":["!pip install tensorflow\n","!pip install tensorflow-addons\n","!pip install opencv-python\n","!pip install scikit-learn\n","!pip install matplotlib"]},{"cell_type":"markdown","id":"37c87a7c-5c90-43ec-88e9-ad0038715bad","metadata":{"id":"37c87a7c-5c90-43ec-88e9-ad0038715bad"},"source":["# Define Path"]},{"cell_type":"code","execution_count":18,"id":"ec3573a6-17e2-4aba-b7f2-67aceccb7dd9","metadata":{"id":"ec3573a6-17e2-4aba-b7f2-67aceccb7dd9","executionInfo":{"status":"ok","timestamp":1716912813895,"user_tz":-420,"elapsed":9,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["import os\n","\n","\n","BASE_PATH = '/content/gdrive/MyDrive/BuildingContourDetectionandHeightEstimationProblem/'\n","IMAGE_PATH = BASE_PATH+\"images/\"\n","DATA_PATH = BASE_PATH+\"data/\"\n","MODEL_PATH = BASE_PATH+\"models/\"\n","MODULE_PATH = BASE_PATH+\"modules/\""]},{"cell_type":"code","execution_count":19,"id":"1af28530-c196-4ed7-bfbb-8efd997205a1","metadata":{"id":"1af28530-c196-4ed7-bfbb-8efd997205a1","executionInfo":{"status":"ok","timestamp":1716912813895,"user_tz":-420,"elapsed":8,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["import sys\n","sys.path.append(MODULE_PATH)"]},{"cell_type":"markdown","id":"da68cbb2-3345-478a-88bb-49548383fe90","metadata":{"id":"da68cbb2-3345-478a-88bb-49548383fe90"},"source":["# Split Dataset"]},{"cell_type":"code","execution_count":20,"id":"75bd047c-351a-4efd-9b77-3802f80a92b9","metadata":{"id":"75bd047c-351a-4efd-9b77-3802f80a92b9","executionInfo":{"status":"ok","timestamp":1716912813895,"user_tz":-420,"elapsed":7,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["# import os\n","# import shutil\n","# import numpy as np\n","# from sklearn.model_selection import train_test_split\n","\n","\n","# # Paths to your dataset\n","# dataset_dir = DATA_PATH + 'source'\n","# images_dir = os.path.join(dataset_dir, 'images')\n","# annotations_dir = os.path.join(dataset_dir, 'annotations')\n","\n","# # Paths for the output directories\n","# output_dir = DATA_PATH\n","# train_images_dir = os.path.join(output_dir, 'train', 'images')\n","# train_annotations_dir = os.path.join(output_dir, 'train', 'annotations')\n","# validation_images_dir = os.path.join(output_dir, 'validation', 'images')\n","# validation_annotations_dir = os.path.join(output_dir, 'validation', 'annotations')\n","\n","# # Create directories if they do not exist\n","# os.makedirs(train_images_dir, exist_ok=True)\n","# os.makedirs(train_annotations_dir, exist_ok=True)\n","# os.makedirs(validation_images_dir, exist_ok=True)\n","# os.makedirs(validation_annotations_dir, exist_ok=True)\n","\n","# # Get a list of all image files and corresponding json files\n","# image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n","# json_files = [f for f in os.listdir(annotations_dir) if f.endswith('.json')]\n","\n","# # Ensure that each image has a corresponding json file\n","# image_files = sorted(image_files)\n","# json_files = sorted(json_files)\n","# pairs = [(img, img.replace('.jpg', '.json').replace('.png', '.json')) for img in image_files]\n","\n","# # Split the dataset\n","# train_pairs, validation_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n","\n","# def copy_files(pairs, image_dest, json_dest):\n","#     for img, json in pairs:\n","#         shutil.copy2(os.path.join(images_dir, img), os.path.join(image_dest, img))\n","#         shutil.copy2(os.path.join(annotations_dir, json), os.path.join(json_dest, json))\n","\n","# # Copy the files to the train and validation directories\n","# copy_files(train_pairs, train_images_dir, train_annotations_dir)\n","# copy_files(validation_pairs, validation_images_dir, validation_annotations_dir)\n","\n","# print(\"Train-validation split completed successfully!\")"]},{"cell_type":"code","execution_count":21,"id":"4d6a8e1c-d10e-4c52-a909-c32b90d91929","metadata":{"id":"4d6a8e1c-d10e-4c52-a909-c32b90d91929","executionInfo":{"status":"ok","timestamp":1716912813895,"user_tz":-420,"elapsed":6,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["# import gc\n","\n","\n","# gc.collect()"]},{"cell_type":"markdown","id":"1a02bb8f-a1bb-4ba8-9a4d-3b1cd0eff8bb","metadata":{"id":"1a02bb8f-a1bb-4ba8-9a4d-3b1cd0eff8bb"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":22,"id":"1531d21e-fcbc-4411-890b-c45ff2de12d9","metadata":{"id":"1531d21e-fcbc-4411-890b-c45ff2de12d9","executionInfo":{"status":"ok","timestamp":1716912813896,"user_tz":-420,"elapsed":7,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["# import os\n","# import json\n","# import numpy as np\n","# import cv2\n","# from sklearn.model_selection import train_test_split\n","# import matplotlib.pyplot as plt\n","\n","\n","# def load_data(image_dir, annotation_dir):\n","#     images = []\n","#     annotations = []\n","#     for filename in os.listdir(image_dir):\n","#         if filename.endswith('.png'):\n","#             img = cv2.imread(os.path.join(image_dir, filename))\n","#             with open(os.path.join(annotation_dir, filename.replace('.png', '.json')), 'r') as f:\n","#                 gt = json.load(f)\n","#             images.append(img)\n","#             annotations.append(gt)\n","#     return images, annotations\n","\n","# def preprocess_image(image):\n","#     image = image / 255.0\n","#     return image\n","\n","# def create_mask_and_height_map(image_shape, contours):\n","#     mask = np.zeros(image_shape[:2], dtype=np.uint8)\n","#     height_map = np.zeros(image_shape[:2], dtype=np.float32)\n","#     for contour in contours:\n","#         points = np.array(contour['points'], dtype=np.int32)\n","#         cv2.fillPoly(mask, [points], 1)\n","#         cv2.fillPoly(height_map, [points], contour['group_id'])\n","#     return mask, height_map\n","\n","# def preprocess_data(image_dir, annotation_dir):\n","#     images, annotations = load_data(image_dir, annotation_dir)\n","#     preprocessed_images = [preprocess_image(img) for img in images]\n","#     masks = []\n","#     height_maps = []\n","#     for gt in annotations:\n","#         mask, height_map = create_mask_and_height_map(preprocessed_images[0].shape, gt['shapes'])\n","#         masks.append(mask)\n","#         height_maps.append(height_map)\n","#     return preprocessed_images, masks, height_maps"]},{"cell_type":"code","execution_count":23,"id":"fac012df-a6c9-4e39-862d-3ddd07f4122a","metadata":{"id":"fac012df-a6c9-4e39-862d-3ddd07f4122a","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":515,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["# train_images_dir = DATA_PATH + 'train/images'\n","# train_annotations_dir = DATA_PATH + 'train/annotations'\n","# train_images, train_masks, train_heights = preprocess_data(train_images_dir, train_annotations_dir)"]},{"cell_type":"code","execution_count":24,"id":"9a9cb7cf-e870-4c12-a15e-9a13d36cf2d0","metadata":{"id":"9a9cb7cf-e870-4c12-a15e-9a13d36cf2d0","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":6,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["# validation_images_dir = DATA_PATH + 'validation/images'\n","# validation_annotations_dir = DATA_PATH + 'validation/annotations'\n","# validation_images, validation_masks, validation_heights = preprocess_data(validation_images_dir, validation_annotations_dir)"]},{"cell_type":"code","source":["import os\n","import json\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","\n","def preprocess_image(image):\n","    image = image / 255.0\n","    return image\n","\n","def create_mask_and_height_map(image_shape, contours):\n","    mask = np.zeros(image_shape[:2], dtype=np.uint8)\n","    height_map = np.zeros(image_shape[:2], dtype=np.float32)\n","    for contour in contours:\n","        points = np.array(contour['points'], dtype=np.int32)\n","        cv2.fillPoly(mask, [points], 1)\n","        cv2.fillPoly(height_map, [points], contour['group_id'])\n","    return mask, height_map\n","\n","def data_generator(image_dir, annotation_dir, batch_size=32):\n","    image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n","    num_samples = len(image_files)\n","\n","    while True:\n","        for offset in range(0, num_samples, batch_size):\n","            batch_images = []\n","            batch_masks = []\n","            batch_height_maps = []\n","\n","            batch_files = image_files[offset:offset + batch_size]\n","            for filename in batch_files:\n","                img_path = os.path.join(image_dir, filename)\n","                annotation_path = os.path.join(annotation_dir, filename.replace('.png', '.json'))\n","\n","                img = cv2.imread(img_path)\n","                if img is None:\n","                    continue\n","\n","                img = preprocess_image(img)\n","\n","                with open(annotation_path, 'r') as f:\n","                    gt = json.load(f)\n","\n","                mask, height_map = create_mask_and_height_map(img.shape, gt['shapes'])\n","\n","                batch_images.append(img)\n","                batch_masks.append(mask)\n","                batch_height_maps.append(height_map)\n","\n","            yield np.array(batch_images), np.expand_dims(np.array(batch_masks), axis=-1), np.expand_dims(np.array(batch_height_maps), axis=-1)"],"metadata":{"id":"oHUxiynvmODM","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":5,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"id":"oHUxiynvmODM","execution_count":25,"outputs":[]},{"cell_type":"code","source":["batch_size = 4"],"metadata":{"id":"VF3MSzUem4dr","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":5,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"id":"VF3MSzUem4dr","execution_count":26,"outputs":[]},{"cell_type":"code","source":["train_images_dir = DATA_PATH + 'train/images'\n","train_annotations_dir = DATA_PATH + 'train/annotations'\n","train_generator = data_generator(train_images_dir, train_annotations_dir, batch_size=batch_size)"],"metadata":{"id":"isyNf_HemUy6","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":5,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"id":"isyNf_HemUy6","execution_count":27,"outputs":[]},{"cell_type":"code","source":["validation_images_dir = DATA_PATH + 'validation/images'\n","validation_annotations_dir = DATA_PATH + 'validation/annotations'\n","validation_generator = data_generator(validation_images_dir, validation_annotations_dir, batch_size=batch_size)"],"metadata":{"id":"B99uRZOymXsY","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":5,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"id":"B99uRZOymXsY","execution_count":28,"outputs":[]},{"cell_type":"markdown","id":"78debc48-c673-4084-8819-079855d59d66","metadata":{"id":"78debc48-c673-4084-8819-079855d59d66"},"source":["# Model Training"]},{"cell_type":"code","execution_count":29,"id":"e3356cf4-daf4-4625-8599-5540f42e6e69","metadata":{"id":"e3356cf4-daf4-4625-8599-5540f42e6e69","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":5,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["# def unet_model(input_shape):\n","#     inputs = tf.keras.Input(input_shape)\n","#     # Encoder\n","#     c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","#     c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","#     p1 = layers.MaxPooling2D((2, 2))(c1)\n","#     # Decoder\n","#     u6 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(p1)\n","#     u6 = layers.concatenate([u6, c1])\n","#     c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u6)\n","#     c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c6)\n","#     contour_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='contour_output')(c6)\n","#     height_output = layers.Conv2D(1, (1, 1), activation='linear', name='height_output')(c6)\n","#     return models.Model(inputs=[inputs], outputs=[contour_output, height_output])\n","\n","# input_shape = (512, 512, 3)\n","# model = unet_model(input_shape)\n","# model.compile(optimizer='adam', loss={'contour_output': 'binary_crossentropy', 'height_output': 'mean_squared_error'}, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":30,"id":"9aa12da7-dbfd-449d-9821-20439008471f","metadata":{"id":"9aa12da7-dbfd-449d-9821-20439008471f","executionInfo":{"status":"ok","timestamp":1716912814405,"user_tz":-420,"elapsed":5,"user":{"displayName":"model trainer","userId":"06698139684495762614"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"037b07cd-c982-4129-e9fe-886dfe350427"},"outputs":[{"output_type":"stream","name":"stdout","text":["Latest checkpoint: /content/gdrive/MyDrive/BuildingContourDetectionandHeightEstimationProblem/models/ckpt_02.h5, initial epoch: 2\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","import re\n","\n","\n","def iou(y_true, y_pred, smooth=1.):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n","\n","\n","def threshold_binarize(x, threshold=0.5):\n","    ge = tf.greater_equal(x, tf.constant(threshold))\n","    y = tf.where(ge, x=tf.ones_like(x), y=tf.zeros_like(x))\n","    return y\n","\n","\n","def iou_thresholded(y_true, y_pred, threshold=0.5, smooth=1.):\n","    y_pred = threshold_binarize(y_pred, threshold)\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n","\n","def dice_coef(y_true, y_pred, smooth=1e-6):\n","    y_true = tf.cast(y_true, dtype=y_pred.dtype)  # Cast y_true to the same dtype as y_pred\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","    dice = (2. * intersection + smooth) / (union + smooth)\n","    return dice\n","\n","def dice_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred)\n","\n","def get_latest_checkpoint(checkpoint_dir):\n","    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.h5')]\n","    if not checkpoint_files:\n","        return None, 0\n","    epochs = [int(re.search(r'ckpt_(\\d+)', f).group(1)) for f in checkpoint_files]\n","    latest_epoch = max(epochs)\n","    latest_checkpoint = os.path.join(checkpoint_dir, f'ckpt_{latest_epoch:02d}.h5')\n","    return latest_checkpoint, latest_epoch\n","\n","checkpoint_prefix = os.path.join(MODEL_PATH, \"ckpt_{epoch:02d}.h5\")\n","callbacks = [\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-8),\n","    tf.keras.callbacks.ModelCheckpoint(checkpoint_prefix, monitor='val_loss', mode='min', verbose=1, save_weights_only=False, save_best_only=False, save_freq='epoch'),\n","    tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=6,  mode='min')\n","]\n","latest_checkpoint, initial_epoch = get_latest_checkpoint(MODEL_PATH)\n","print(f\"Latest checkpoint: {latest_checkpoint}, initial epoch: {initial_epoch}\")"]},{"cell_type":"code","execution_count":31,"id":"plItD12EPg5-","metadata":{"id":"plItD12EPg5-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716912839148,"user_tz":-420,"elapsed":24746,"user":{"displayName":"model trainer","userId":"06698139684495762614"}},"outputId":"0686ca10-41bb-4e32-e0cf-c1b6e68d4ce6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"AttentionResUNet\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_6 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n","                                                                                                  \n"," conv2d_240 (Conv2D)         (None, 512, 512, 64)         1792      ['input_6[0][0]']             \n","                                                                                                  \n"," batch_normalization_180 (B  (None, 512, 512, 64)         256       ['conv2d_240[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_150 (Activation  (None, 512, 512, 64)         0         ['batch_normalization_180[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_241 (Conv2D)         (None, 512, 512, 64)         36928     ['activation_150[0][0]']      \n","                                                                                                  \n"," conv2d_242 (Conv2D)         (None, 512, 512, 64)         256       ['input_6[0][0]']             \n","                                                                                                  \n"," batch_normalization_181 (B  (None, 512, 512, 64)         256       ['conv2d_241[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_182 (B  (None, 512, 512, 64)         256       ['conv2d_242[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_45 (Dropout)        (None, 512, 512, 64)         0         ['batch_normalization_181[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_65 (Add)                (None, 512, 512, 64)         0         ['batch_normalization_182[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_45[0][0]']          \n","                                                                                                  \n"," activation_151 (Activation  (None, 512, 512, 64)         0         ['add_65[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," max_pooling2d_20 (MaxPooli  (None, 256, 256, 64)         0         ['activation_151[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," conv2d_243 (Conv2D)         (None, 256, 256, 128)        73856     ['max_pooling2d_20[0][0]']    \n","                                                                                                  \n"," batch_normalization_183 (B  (None, 256, 256, 128)        512       ['conv2d_243[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_152 (Activation  (None, 256, 256, 128)        0         ['batch_normalization_183[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_244 (Conv2D)         (None, 256, 256, 128)        147584    ['activation_152[0][0]']      \n","                                                                                                  \n"," conv2d_245 (Conv2D)         (None, 256, 256, 128)        8320      ['max_pooling2d_20[0][0]']    \n","                                                                                                  \n"," batch_normalization_184 (B  (None, 256, 256, 128)        512       ['conv2d_244[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_185 (B  (None, 256, 256, 128)        512       ['conv2d_245[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_46 (Dropout)        (None, 256, 256, 128)        0         ['batch_normalization_184[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_66 (Add)                (None, 256, 256, 128)        0         ['batch_normalization_185[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_46[0][0]']          \n","                                                                                                  \n"," activation_153 (Activation  (None, 256, 256, 128)        0         ['add_66[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," max_pooling2d_21 (MaxPooli  (None, 128, 128, 128)        0         ['activation_153[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," conv2d_246 (Conv2D)         (None, 128, 128, 256)        295168    ['max_pooling2d_21[0][0]']    \n","                                                                                                  \n"," batch_normalization_186 (B  (None, 128, 128, 256)        1024      ['conv2d_246[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_154 (Activation  (None, 128, 128, 256)        0         ['batch_normalization_186[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_247 (Conv2D)         (None, 128, 128, 256)        590080    ['activation_154[0][0]']      \n","                                                                                                  \n"," conv2d_248 (Conv2D)         (None, 128, 128, 256)        33024     ['max_pooling2d_21[0][0]']    \n","                                                                                                  \n"," batch_normalization_187 (B  (None, 128, 128, 256)        1024      ['conv2d_247[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_188 (B  (None, 128, 128, 256)        1024      ['conv2d_248[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_47 (Dropout)        (None, 128, 128, 256)        0         ['batch_normalization_187[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_67 (Add)                (None, 128, 128, 256)        0         ['batch_normalization_188[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_47[0][0]']          \n","                                                                                                  \n"," activation_155 (Activation  (None, 128, 128, 256)        0         ['add_67[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," max_pooling2d_22 (MaxPooli  (None, 64, 64, 256)          0         ['activation_155[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," conv2d_249 (Conv2D)         (None, 64, 64, 512)          1180160   ['max_pooling2d_22[0][0]']    \n","                                                                                                  \n"," batch_normalization_189 (B  (None, 64, 64, 512)          2048      ['conv2d_249[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_156 (Activation  (None, 64, 64, 512)          0         ['batch_normalization_189[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_250 (Conv2D)         (None, 64, 64, 512)          2359808   ['activation_156[0][0]']      \n","                                                                                                  \n"," conv2d_251 (Conv2D)         (None, 64, 64, 512)          131584    ['max_pooling2d_22[0][0]']    \n","                                                                                                  \n"," batch_normalization_190 (B  (None, 64, 64, 512)          2048      ['conv2d_250[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_191 (B  (None, 64, 64, 512)          2048      ['conv2d_251[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_48 (Dropout)        (None, 64, 64, 512)          0         ['batch_normalization_190[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_68 (Add)                (None, 64, 64, 512)          0         ['batch_normalization_191[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_48[0][0]']          \n","                                                                                                  \n"," activation_157 (Activation  (None, 64, 64, 512)          0         ['add_68[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," max_pooling2d_23 (MaxPooli  (None, 32, 32, 512)          0         ['activation_157[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," conv2d_252 (Conv2D)         (None, 32, 32, 1024)         4719616   ['max_pooling2d_23[0][0]']    \n","                                                                                                  \n"," batch_normalization_192 (B  (None, 32, 32, 1024)         4096      ['conv2d_252[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_158 (Activation  (None, 32, 32, 1024)         0         ['batch_normalization_192[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_253 (Conv2D)         (None, 32, 32, 1024)         9438208   ['activation_158[0][0]']      \n","                                                                                                  \n"," conv2d_254 (Conv2D)         (None, 32, 32, 1024)         525312    ['max_pooling2d_23[0][0]']    \n","                                                                                                  \n"," batch_normalization_193 (B  (None, 32, 32, 1024)         4096      ['conv2d_253[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_194 (B  (None, 32, 32, 1024)         4096      ['conv2d_254[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_49 (Dropout)        (None, 32, 32, 1024)         0         ['batch_normalization_193[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_69 (Add)                (None, 32, 32, 1024)         0         ['batch_normalization_194[0][0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["                                                                    ]',                           \n","                                                                     'dropout_49[0][0]']          \n","                                                                                                  \n"," activation_159 (Activation  (None, 32, 32, 1024)         0         ['add_69[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_255 (Conv2D)         (None, 32, 32, 512)          524800    ['activation_159[0][0]']      \n","                                                                                                  \n"," batch_normalization_195 (B  (None, 32, 32, 512)          2048      ['conv2d_255[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_160 (Activation  (None, 32, 32, 512)          0         ['batch_normalization_195[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_257 (Conv2D)         (None, 32, 32, 512)          262656    ['activation_160[0][0]']      \n","                                                                                                  \n"," conv2d_transpose_20 (Conv2  (None, 32, 32, 512)          2359808   ['conv2d_257[0][0]']          \n"," DTranspose)                                                                                      \n","                                                                                                  \n"," conv2d_256 (Conv2D)         (None, 32, 32, 512)          1049088   ['activation_157[0][0]']      \n","                                                                                                  \n"," add_70 (Add)                (None, 32, 32, 512)          0         ['conv2d_transpose_20[0][0]', \n","                                                                     'conv2d_256[0][0]']          \n","                                                                                                  \n"," activation_161 (Activation  (None, 32, 32, 512)          0         ['add_70[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_258 (Conv2D)         (None, 32, 32, 1)            513       ['activation_161[0][0]']      \n","                                                                                                  \n"," activation_162 (Activation  (None, 32, 32, 1)            0         ['conv2d_258[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," up_sampling2d_40 (UpSampli  (None, 64, 64, 1)            0         ['activation_162[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," lambda_20 (Lambda)          (None, 64, 64, 512)          0         ['up_sampling2d_40[0][0]']    \n","                                                                                                  \n"," multiply_20 (Multiply)      (None, 64, 64, 512)          0         ['lambda_20[0][0]',           \n","                                                                     'activation_157[0][0]']      \n","                                                                                                  \n"," conv2d_259 (Conv2D)         (None, 64, 64, 512)          262656    ['multiply_20[0][0]']         \n","                                                                                                  \n"," up_sampling2d_41 (UpSampli  (None, 64, 64, 1024)         0         ['activation_159[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," batch_normalization_196 (B  (None, 64, 64, 512)          2048      ['conv2d_259[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," concatenate_20 (Concatenat  (None, 64, 64, 1536)         0         ['up_sampling2d_41[0][0]',    \n"," e)                                                                  'batch_normalization_196[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," conv2d_260 (Conv2D)         (None, 64, 64, 512)          7078400   ['concatenate_20[0][0]']      \n","                                                                                                  \n"," batch_normalization_197 (B  (None, 64, 64, 512)          2048      ['conv2d_260[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_163 (Activation  (None, 64, 64, 512)          0         ['batch_normalization_197[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_261 (Conv2D)         (None, 64, 64, 512)          2359808   ['activation_163[0][0]']      \n","                                                                                                  \n"," conv2d_262 (Conv2D)         (None, 64, 64, 512)          786944    ['concatenate_20[0][0]']      \n","                                                                                                  \n"," batch_normalization_198 (B  (None, 64, 64, 512)          2048      ['conv2d_261[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_199 (B  (None, 64, 64, 512)          2048      ['conv2d_262[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_50 (Dropout)        (None, 64, 64, 512)          0         ['batch_normalization_198[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_71 (Add)                (None, 64, 64, 512)          0         ['batch_normalization_199[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_50[0][0]']          \n","                                                                                                  \n"," activation_164 (Activation  (None, 64, 64, 512)          0         ['add_71[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_263 (Conv2D)         (None, 64, 64, 256)          131328    ['activation_164[0][0]']      \n","                                                                                                  \n"," batch_normalization_200 (B  (None, 64, 64, 256)          1024      ['conv2d_263[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_165 (Activation  (None, 64, 64, 256)          0         ['batch_normalization_200[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_265 (Conv2D)         (None, 64, 64, 256)          65792     ['activation_165[0][0]']      \n","                                                                                                  \n"," conv2d_transpose_21 (Conv2  (None, 64, 64, 256)          590080    ['conv2d_265[0][0]']          \n"," DTranspose)                                                                                      \n","                                                                                                  \n"," conv2d_264 (Conv2D)         (None, 64, 64, 256)          262400    ['activation_155[0][0]']      \n","                                                                                                  \n"," add_72 (Add)                (None, 64, 64, 256)          0         ['conv2d_transpose_21[0][0]', \n","                                                                     'conv2d_264[0][0]']          \n","                                                                                                  \n"," activation_166 (Activation  (None, 64, 64, 256)          0         ['add_72[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_266 (Conv2D)         (None, 64, 64, 1)            257       ['activation_166[0][0]']      \n","                                                                                                  \n"," activation_167 (Activation  (None, 64, 64, 1)            0         ['conv2d_266[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," up_sampling2d_42 (UpSampli  (None, 128, 128, 1)          0         ['activation_167[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," lambda_21 (Lambda)          (None, 128, 128, 256)        0         ['up_sampling2d_42[0][0]']    \n","                                                                                                  \n"," multiply_21 (Multiply)      (None, 128, 128, 256)        0         ['lambda_21[0][0]',           \n","                                                                     'activation_155[0][0]']      \n","                                                                                                  \n"," conv2d_267 (Conv2D)         (None, 128, 128, 256)        65792     ['multiply_21[0][0]']         \n","                                                                                                  \n"," up_sampling2d_43 (UpSampli  (None, 128, 128, 512)        0         ['activation_164[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," batch_normalization_201 (B  (None, 128, 128, 256)        1024      ['conv2d_267[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," concatenate_21 (Concatenat  (None, 128, 128, 768)        0         ['up_sampling2d_43[0][0]',    \n"," e)                                                                  'batch_normalization_201[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," conv2d_268 (Conv2D)         (None, 128, 128, 256)        1769728   ['concatenate_21[0][0]']      \n","                                                                                                  \n"," batch_normalization_202 (B  (None, 128, 128, 256)        1024      ['conv2d_268[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_168 (Activation  (None, 128, 128, 256)        0         ['batch_normalization_202[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_269 (Conv2D)         (None, 128, 128, 256)        590080    ['activation_168[0][0]']      \n","                                                                                                  \n"," conv2d_270 (Conv2D)         (None, 128, 128, 256)        196864    ['concatenate_21[0][0]']      \n","                                                                                                  \n"," batch_normalization_203 (B  (None, 128, 128, 256)        1024      ['conv2d_269[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_204 (B  (None, 128, 128, 256)        1024      ['conv2d_270[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_51 (Dropout)        (None, 128, 128, 256)        0         ['batch_normalization_203[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_73 (Add)                (None, 128, 128, 256)        0         ['batch_normalization_204[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_51[0][0]']          \n","                                                                                                  \n"," activation_169 (Activation  (None, 128, 128, 256)        0         ['add_73[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_271 (Conv2D)         (None, 128, 128, 128)        32896     ['activation_169[0][0]']      \n","                                                                                                  \n"," batch_normalization_205 (B  (None, 128, 128, 128)        512       ['conv2d_271[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_170 (Activation  (None, 128, 128, 128)        0         ['batch_normalization_205[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_273 (Conv2D)         (None, 128, 128, 128)        16512     ['activation_170[0][0]']      \n","                                                                                                  \n"," conv2d_transpose_22 (Conv2  (None, 128, 128, 128)        147584    ['conv2d_273[0][0]']          \n"," DTranspose)                                                                                      \n","                                                                                                  \n"," conv2d_272 (Conv2D)         (None, 128, 128, 128)        65664     ['activation_153[0][0]']      \n","                                                                                                  \n"," add_74 (Add)                (None, 128, 128, 128)        0         ['conv2d_transpose_22[0][0]', \n","                                                                     'conv2d_272[0][0]']          \n","                                                                                                  \n"," activation_171 (Activation  (None, 128, 128, 128)        0         ['add_74[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_274 (Conv2D)         (None, 128, 128, 1)          129       ['activation_171[0][0]']      \n","                                                                                                  \n"," activation_172 (Activation  (None, 128, 128, 1)          0         ['conv2d_274[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," up_sampling2d_44 (UpSampli  (None, 256, 256, 1)          0         ['activation_172[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," lambda_22 (Lambda)          (None, 256, 256, 128)        0         ['up_sampling2d_44[0][0]']    \n","                                                                                                  \n"," multiply_22 (Multiply)      (None, 256, 256, 128)        0         ['lambda_22[0][0]',           \n","                                                                     'activation_153[0][0]']      \n","                                                                                                  \n"," conv2d_275 (Conv2D)         (None, 256, 256, 128)        16512     ['multiply_22[0][0]']         \n","                                                                                                  \n"," up_sampling2d_45 (UpSampli  (None, 256, 256, 256)        0         ['activation_169[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," batch_normalization_206 (B  (None, 256, 256, 128)        512       ['conv2d_275[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," concatenate_22 (Concatenat  (None, 256, 256, 384)        0         ['up_sampling2d_45[0][0]',    \n"," e)                                                                  'batch_normalization_206[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," conv2d_276 (Conv2D)         (None, 256, 256, 128)        442496    ['concatenate_22[0][0]']      \n","                                                                                                  \n"," batch_normalization_207 (B  (None, 256, 256, 128)        512       ['conv2d_276[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_173 (Activation  (None, 256, 256, 128)        0         ['batch_normalization_207[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_277 (Conv2D)         (None, 256, 256, 128)        147584    ['activation_173[0][0]']      \n","                                                                                                  \n"," conv2d_278 (Conv2D)         (None, 256, 256, 128)        49280     ['concatenate_22[0][0]']      \n","                                                                                                  \n"," batch_normalization_208 (B  (None, 256, 256, 128)        512       ['conv2d_277[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_209 (B  (None, 256, 256, 128)        512       ['conv2d_278[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_52 (Dropout)        (None, 256, 256, 128)        0         ['batch_normalization_208[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_75 (Add)                (None, 256, 256, 128)        0         ['batch_normalization_209[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_52[0][0]']          \n","                                                                                                  \n"," activation_174 (Activation  (None, 256, 256, 128)        0         ['add_75[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_279 (Conv2D)         (None, 256, 256, 64)         8256      ['activation_174[0][0]']      \n","                                                                                                  \n"," batch_normalization_210 (B  (None, 256, 256, 64)         256       ['conv2d_279[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_175 (Activation  (None, 256, 256, 64)         0         ['batch_normalization_210[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_281 (Conv2D)         (None, 256, 256, 64)         4160      ['activation_175[0][0]']      \n","                                                                                                  \n"," conv2d_transpose_23 (Conv2  (None, 256, 256, 64)         36928     ['conv2d_281[0][0]']          \n"," DTranspose)                                                                                      \n","                                                                                                  \n"," conv2d_280 (Conv2D)         (None, 256, 256, 64)         16448     ['activation_151[0][0]']      \n","                                                                                                  \n"," add_76 (Add)                (None, 256, 256, 64)         0         ['conv2d_transpose_23[0][0]', \n","                                                                     'conv2d_280[0][0]']          \n","                                                                                                  \n"," activation_176 (Activation  (None, 256, 256, 64)         0         ['add_76[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_282 (Conv2D)         (None, 256, 256, 1)          65        ['activation_176[0][0]']      \n","                                                                                                  \n"," activation_177 (Activation  (None, 256, 256, 1)          0         ['conv2d_282[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," up_sampling2d_46 (UpSampli  (None, 512, 512, 1)          0         ['activation_177[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," lambda_23 (Lambda)          (None, 512, 512, 64)         0         ['up_sampling2d_46[0][0]']    \n","                                                                                                  \n"," multiply_23 (Multiply)      (None, 512, 512, 64)         0         ['lambda_23[0][0]',           \n","                                                                     'activation_151[0][0]']      \n","                                                                                                  \n"," conv2d_283 (Conv2D)         (None, 512, 512, 64)         4160      ['multiply_23[0][0]']         \n","                                                                                                  \n"," up_sampling2d_47 (UpSampli  (None, 512, 512, 128)        0         ['activation_174[0][0]']      \n"," ng2D)                                                                                            \n","                                                                                                  \n"," batch_normalization_211 (B  (None, 512, 512, 64)         256       ['conv2d_283[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," concatenate_23 (Concatenat  (None, 512, 512, 192)        0         ['up_sampling2d_47[0][0]',    \n"," e)                                                                  'batch_normalization_211[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," conv2d_284 (Conv2D)         (None, 512, 512, 64)         110656    ['concatenate_23[0][0]']      \n","                                                                                                  \n"," batch_normalization_212 (B  (None, 512, 512, 64)         256       ['conv2d_284[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," activation_178 (Activation  (None, 512, 512, 64)         0         ['batch_normalization_212[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," conv2d_285 (Conv2D)         (None, 512, 512, 64)         36928     ['activation_178[0][0]']      \n","                                                                                                  \n"," conv2d_286 (Conv2D)         (None, 512, 512, 64)         12352     ['concatenate_23[0][0]']      \n","                                                                                                  \n"," batch_normalization_213 (B  (None, 512, 512, 64)         256       ['conv2d_285[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," batch_normalization_214 (B  (None, 512, 512, 64)         256       ['conv2d_286[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," dropout_53 (Dropout)        (None, 512, 512, 64)         0         ['batch_normalization_213[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," add_77 (Add)                (None, 512, 512, 64)         0         ['batch_normalization_214[0][0\n","                                                                    ]',                           \n","                                                                     'dropout_53[0][0]']          \n","                                                                                                  \n"," activation_179 (Activation  (None, 512, 512, 64)         0         ['add_77[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_287 (Conv2D)         (None, 512, 512, 1)          65        ['activation_179[0][0]']      \n","                                                                                                  \n"," batch_normalization_215 (B  (None, 512, 512, 1)          4         ['conv2d_287[0][0]']          \n"," atchNormalization)                                                                               \n","                                                                                                  \n"," contour_output (Activation  (None, 512, 512, 1)          0         ['batch_normalization_215[0][0\n"," )                                                                  ]']                           \n","                                                                                                  \n"," height_output (Activation)  (None, 512, 512, 1)          0         ['batch_normalization_215[0][0\n","                                                                    ]']                           \n","                                                                                                  \n","==================================================================================================\n","Total params: 39090377 (149.12 MB)\n","Trainable params: 39068871 (149.04 MB)\n","Non-trainable params: 21506 (84.01 KB)\n","__________________________________________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import initializers\n","from tensorflow.keras import layers, models\n","import os\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.utils import custom_object_scope\n","from tensorflow_addons.optimizers import LazyAdam\n","\n","\n","def conv_block(x, filter_size, size, dropout, batch_norm=False):\n","\n","    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n","    if batch_norm is True:\n","        conv = layers.BatchNormalization(axis=3)(conv)\n","    conv = layers.Activation(\"relu\")(conv)\n","\n","    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n","    if batch_norm is True:\n","        conv = layers.BatchNormalization(axis=3)(conv)\n","    conv = layers.Activation(\"relu\")(conv)\n","\n","    if dropout > 0:\n","        conv = layers.Dropout(dropout)(conv)\n","\n","    return conv\n","\n","\n","def repeat_elem(tensor, rep):\n","    # lambda function to repeat Repeats the elements of a tensor along an axis\n","    #by a factor of rep.\n","    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape\n","    #(None, 256,256,6), if specified axis=3 and rep=2.\n","\n","     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n","                          arguments={'repnum': rep})(tensor)\n","\n","\n","def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n","    '''\n","    Residual convolutional layer.\n","    Two variants....\n","    Either put activation function before the addition with shortcut\n","    or after the addition (which would be as proposed in the original resNet).\n","\n","    1. conv - BN - Activation - conv - BN - Activation\n","                                          - shortcut  - BN - shortcut+BN\n","\n","    2. conv - BN - Activation - conv - BN\n","                                     - shortcut  - BN - shortcut+BN - Activation\n","\n","    Check fig 4 in https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n","    '''\n","\n","    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n","    if batch_norm is True:\n","        conv = layers.BatchNormalization(axis=3)(conv)\n","    conv = layers.Activation('relu')(conv)\n","\n","    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n","    if batch_norm is True:\n","        conv = layers.BatchNormalization(axis=3)(conv)\n","    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n","    if dropout > 0:\n","        conv = layers.Dropout(dropout)(conv)\n","\n","    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n","    if batch_norm is True:\n","        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n","\n","    res_path = layers.add([shortcut, conv])\n","    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n","    return res_path\n","\n","def gating_signal(input, out_size, batch_norm=False):\n","    \"\"\"\n","    resize the down layer feature map into the same dimension as the up layer feature map\n","    using 1x1 conv\n","    :return: the gating feature map with the same dimension of the up layer feature map\n","    \"\"\"\n","    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n","    if batch_norm:\n","        x = layers.BatchNormalization()(x)\n","    x = layers.Activation('relu')(x)\n","    return x\n","\n","def attention_block(x, gating, inter_shape):\n","    shape_x = K.int_shape(x)\n","    shape_g = K.int_shape(gating)\n","\n","# Getting the x signal to the same shape as the gating signal\n","    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n","    shape_theta_x = K.int_shape(theta_x)\n","\n","# Getting the gating signal to the same number of filters as the inter_shape\n","    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n","    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n","                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n","                                 padding='same')(phi_g)  # 16\n","\n","    concat_xg = layers.add([upsample_g, theta_x])\n","    act_xg = layers.Activation('relu')(concat_xg)\n","    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n","    sigmoid_xg = layers.Activation('sigmoid')(psi)\n","    shape_sigmoid = K.int_shape(sigmoid_xg)\n","    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n","\n","    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n","\n","    y = layers.multiply([upsample_psi, x])\n","\n","    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n","    result_bn = layers.BatchNormalization()(result)\n","    return result_bn\n","\n","def Attention_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True, filter_num=64):\n","    '''\n","    Rsidual UNet, with attention\n","\n","    '''\n","    # network structure\n","    FILTER_NUM = filter_num # number of basic filters for the first layer\n","    FILTER_SIZE = 3 # size of the convolutional filter\n","    UP_SAMP_SIZE = 2 # size of upsampling filters\n","    # input data\n","    # dimension of the image depth\n","    inputs = layers.Input(input_shape, dtype=tf.float32)\n","    axis = 3\n","\n","    # Downsampling layers\n","    # DownRes 1, double residual convolution + pooling\n","    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n","    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n","    # DownRes 2\n","    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n","    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n","    # DownRes 3\n","    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n","    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n","    # DownRes 4\n","    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n","    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n","    # DownRes 5, convolution only\n","    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n","\n","    # Upsampling layers\n","    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n","    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n","    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n","    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n","    up_16 = layers.concatenate([up_16, att_16], axis=axis)\n","    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n","    # UpRes 7\n","    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n","    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n","    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n","    up_32 = layers.concatenate([up_32, att_32], axis=axis)\n","    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n","    # UpRes 8\n","    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n","    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n","    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n","    up_64 = layers.concatenate([up_64, att_64], axis=axis)\n","    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n","    # UpRes 9\n","    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n","    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n","    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n","    up_128 = layers.concatenate([up_128, att_128], axis=axis)\n","    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n","\n","    # 1*1 convolutional layers\n","\n","    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n","    conv_final = layers.BatchNormalization(axis=axis)(conv_final)\n","    contour_output = layers.Activation('sigmoid', name='contour_output')(conv_final)\n","    height_output = layers.Activation('linear', name='height_output')(conv_final)\n","\n","    # Model integration\n","    model = models.Model(inputs, [contour_output, height_output], name=\"AttentionResUNet\")\n","    return model\n","\n","if __name__ == \"__main__\":\n","    input_shape = (512, 512, 3)\n","    model = Attention_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.1, batch_norm=True, filter_num=64)\n","    if latest_checkpoint and os.path.exists(latest_checkpoint):\n","        with custom_object_scope({'dice_loss': dice_loss, 'iou':iou, 'iou_thresholded':iou_thresholded}):\n","          model = load_model(latest_checkpoint)\n","    model.compile(optimizer=LazyAdam(lr=1e-3),\n","                  loss={'contour_output': dice_loss, 'height_output': 'mean_squared_error'},\n","                  metrics={'contour_output': [iou, iou_thresholded, tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.Precision(name='precision')], 'height_output': 'accuracy'})\n","    model.summary()"]},{"cell_type":"code","execution_count":32,"id":"G8t5UGEBPSs3","metadata":{"id":"G8t5UGEBPSs3","executionInfo":{"status":"ok","timestamp":1716912839148,"user_tz":-420,"elapsed":4,"user":{"displayName":"model trainer","userId":"06698139684495762614"}}},"outputs":[],"source":["# # Train the model\n","# history = model.fit(\n","#     np.array(train_images),\n","#     {'contour_output': np.array(train_masks), 'height_output': np.array(train_heights)},\n","#     epochs=100, batch_size=32,\n","#     validation_data=(np.array(validation_images), {'contour_output': np.array(validation_masks), 'height_output': np.array(validation_heights)}),\n","#     callbacks=callbacks\n","# )"]},{"cell_type":"code","source":["# Train the model\n","steps_per_epoch = len(os.listdir(train_images_dir)) // batch_size\n","validation_steps = len(os.listdir(validation_images_dir)) // batch_size\n","history = model.fit(\n","    train_generator,\n","    epochs=100,\n","    initial_epoch=initial_epoch,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=callbacks\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiKZNSIinIJ-","outputId":"c0f08372-6188-4a43-dcae-53c6fe49889e"},"id":"IiKZNSIinIJ-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 3/100\n","440/440 [==============================] - ETA: 0s - loss: 2.8197 - contour_output_loss: 2.6022 - height_output_loss: 0.2175 - contour_output_iou: 0.2128 - contour_output_iou_thresholded: 0.2351 - contour_output_recall: 0.9922 - contour_output_precision: 0.2355 - height_output_accuracy: 0.3737\n","Epoch 3: saving model to /content/gdrive/MyDrive/BuildingContourDetectionandHeightEstimationProblem/models/ckpt_03.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r440/440 [==============================] - 1782s 4s/step - loss: 2.8197 - contour_output_loss: 2.6022 - height_output_loss: 0.2175 - contour_output_iou: 0.2128 - contour_output_iou_thresholded: 0.2351 - contour_output_recall: 0.9922 - contour_output_precision: 0.2355 - height_output_accuracy: 0.3737 - val_loss: 2.8479 - val_contour_output_loss: 2.8288 - val_height_output_loss: 0.0190 - val_contour_output_iou: 0.2069 - val_contour_output_iou_thresholded: 0.2244 - val_contour_output_recall: 0.9987 - val_contour_output_precision: 0.2252 - val_height_output_accuracy: 0.2978 - lr: 0.0010\n","Epoch 4/100\n","440/440 [==============================] - ETA: 0s - loss: 2.7284 - contour_output_loss: 2.6266 - height_output_loss: 0.1017 - contour_output_iou: 0.2083 - contour_output_iou_thresholded: 0.2272 - contour_output_recall: 0.9967 - contour_output_precision: 0.2275 - height_output_accuracy: 0.3153\n","Epoch 4: saving model to /content/gdrive/MyDrive/BuildingContourDetectionandHeightEstimationProblem/models/ckpt_04.h5\n","440/440 [==============================] - 922s 2s/step - loss: 2.7284 - contour_output_loss: 2.6266 - height_output_loss: 0.1017 - contour_output_iou: 0.2083 - contour_output_iou_thresholded: 0.2272 - contour_output_recall: 0.9967 - contour_output_precision: 0.2275 - height_output_accuracy: 0.3153 - val_loss: 2.8394 - val_contour_output_loss: 2.7994 - val_height_output_loss: 0.0401 - val_contour_output_iou: 0.2122 - val_contour_output_iou_thresholded: 0.2277 - val_contour_output_recall: 0.9986 - val_contour_output_precision: 0.2286 - val_height_output_accuracy: 0.3674 - lr: 0.0010\n","Epoch 5/100\n","440/440 [==============================] - ETA: 0s - loss: 2.6981 - contour_output_loss: 2.6377 - height_output_loss: 0.0604 - contour_output_iou: 0.2064 - contour_output_iou_thresholded: 0.2239 - contour_output_recall: 0.9980 - contour_output_precision: 0.2241 - height_output_accuracy: 0.3130\n","Epoch 5: saving model to /content/gdrive/MyDrive/BuildingContourDetectionandHeightEstimationProblem/models/ckpt_05.h5\n","440/440 [==============================] - 929s 2s/step - loss: 2.6981 - contour_output_loss: 2.6377 - height_output_loss: 0.0604 - contour_output_iou: 0.2064 - contour_output_iou_thresholded: 0.2239 - contour_output_recall: 0.9980 - contour_output_precision: 0.2241 - height_output_accuracy: 0.3130 - val_loss: 2.8400 - val_contour_output_loss: 2.8292 - val_height_output_loss: 0.0109 - val_contour_output_iou: 0.2073 - val_contour_output_iou_thresholded: 0.2244 - val_contour_output_recall: 0.9998 - val_contour_output_precision: 0.2254 - val_height_output_accuracy: 0.2872 - lr: 0.0010\n","Epoch 6/100\n","421/440 [===========================>..] - ETA: 37s - loss: 2.6786 - contour_output_loss: 2.6300 - height_output_loss: 0.0486 - contour_output_iou: 0.2073 - contour_output_iou_thresholded: 0.2263 - contour_output_recall: 0.9982 - contour_output_precision: 0.2265 - height_output_accuracy: 0.2997"]}]},{"cell_type":"markdown","id":"e6c35bc6-756b-48e4-9709-f6b76cde96d8","metadata":{"id":"e6c35bc6-756b-48e4-9709-f6b76cde96d8"},"source":["# Inference and Post-processing"]},{"cell_type":"code","execution_count":null,"id":"45cda4e7-b649-49b6-90af-e770b374122f","metadata":{"id":"45cda4e7-b649-49b6-90af-e770b374122f"},"outputs":[],"source":["import os\n","import json\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","import cv2\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"26338554-e959-40f8-8e3a-fd260124cd33","metadata":{"id":"26338554-e959-40f8-8e3a-fd260124cd33"},"outputs":[],"source":["model = tf.keras.models.load_model(MODEL_PATH+'ckpt_01.h5', compile=False)"]},{"cell_type":"code","execution_count":null,"id":"6c45e0c5-ec98-4759-94fb-94cd9ea81c96","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8028,"status":"ok","timestamp":1716732170921,"user":{"displayName":"model trainer","userId":"06698139684495762614"},"user_tz":-420},"id":"6c45e0c5-ec98-4759-94fb-94cd9ea81c96","outputId":"6e891c83-1d2c-4eef-d708-5d8fb368a789"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 4s 4s/step\n"]}],"source":["def preprocess_image(image):\n","    image = image / 255.0\n","    return image\n","\n","def predict_and_generate_output(model, test_image_dir, output_dir):\n","    image_dir =  [os.path.join(test_image_dir, img) for img in os.listdir(test_image_dir) if img.endswith('.png')]\n","    test_images = [cv2.imread(path) for path in image_dir]\n","    test_images = [preprocess_image(img) for img in test_images]\n","    predictions = model.predict(np.array(test_images))\n","    contour_preds = predictions[0]\n","    height_preds = predictions[1]\n","\n","    for i, img in enumerate(test_images):\n","        contours, _ = cv2.findContours((contour_preds[i, :, :, 0] > 0.5).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        shapes = []\n","        for contour in contours:\n","            contour = contour.squeeze()\n","            if len(contour.shape) == 1:\n","                contour = contour[np.newaxis, :]\n","            points = contour.tolist()\n","            height = np.mean(height_preds[i][contour[:, 1], contour[:, 0]])\n","            shape = {\n","                \"label\": \"building\",\n","                \"points\": points,\n","                \"group_id\": int(height),\n","                \"shape_type\": \"polygon\",\n","                \"flags\": {}\n","            }\n","            shapes.append(shape)\n","\n","        output_data = {\n","            \"version\": \"5.0.1\",\n","            \"flags\": {},\n","            \"shapes\": shapes,\n","            \"imagePath\": os.path.basename(image_dir[i]),\n","            \"imageData\": None,\n","            \"imageHeight\": 512,\n","            \"imageWidth\": 512\n","        }\n","\n","        output_path = os.path.join(output_dir, os.path.basename(image_dir[i]).replace('.png', '.json'))\n","        with open(output_path, 'w') as outfile:\n","            json.dump(output_data, outfile)\n","\n","# Example usage\n","test_image_dir = DATA_PATH + 'validation/images'\n","test_output_dir = DATA_PATH + 'validation/predictions'\n","predict_and_generate_output(model, test_image_dir, test_output_dir)"]},{"cell_type":"code","execution_count":null,"id":"66fdc687-e5a2-471f-9425-be831dfed8f4","metadata":{"id":"66fdc687-e5a2-471f-9425-be831dfed8f4"},"outputs":[],"source":["import scorer"]},{"cell_type":"code","execution_count":null,"id":"6cff8573-5fa8-41c4-8556-ef2851b688d2","metadata":{"id":"6cff8573-5fa8-41c4-8556-ef2851b688d2"},"outputs":[],"source":["test_annotations_dir = DATA_PATH + 'validation/annotations'\n","scorer.main(test_annotations_dir, test_output_dir)"]},{"cell_type":"markdown","id":"996997f9-325e-4605-8e15-bec3ee15194c","metadata":{"id":"996997f9-325e-4605-8e15-bec3ee15194c"},"source":["# Visualize"]},{"cell_type":"code","execution_count":null,"id":"3442a12d-3c26-43de-8e3a-a476b11f00d7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1w4ghISy1bG-BYeLIY9njVpOTo8xq_FLs"},"executionInfo":{"elapsed":10574,"status":"ok","timestamp":1716732208243,"user":{"displayName":"model trainer","userId":"06698139684495762614"},"user_tz":-420},"id":"3442a12d-3c26-43de-8e3a-a476b11f00d7","outputId":"9ca48bd0-e2ad-4625-cfaa-d40e9763ecfe"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","from matplotlib.patches import Polygon\n","import numpy as np\n","import json\n","\n","\n","def visualize_buildings(image_path, ground_truth, predictions):\n","    \"\"\"\n","    Visualize ground truth and predicted building contours and heights on an image.\n","\n","    :param image_path: Path to the input image\n","    :param ground_truth: Ground truth data (list of polygons with heights)\n","    :param predictions: Predicted data (list of polygons with heights)\n","    \"\"\"\n","    # Load the image\n","    image = plt.imread(image_path)\n","\n","    # Create a plot\n","    fig, ax = plt.subplots(figsize=(12, 12))\n","    ax.imshow(image)\n","\n","    # Plot ground truth polygons\n","    for building in ground_truth:\n","        polygon = Polygon(building['points'], closed=True, edgecolor='g', facecolor='none', linewidth=2, label='Ground Truth')\n","        ax.add_patch(polygon)\n","        centroid = np.mean(building['points'], axis=0)\n","        ax.text(centroid[0], centroid[1], str(building['height']), color='g', fontsize=12, ha='center')\n","\n","    # Plot predicted polygons\n","    for building in predictions:\n","        polygon = Polygon(building['points'], closed=True, edgecolor='r', facecolor='none', linewidth=2, linestyle='--', label='Prediction')\n","        ax.add_patch(polygon)\n","        centroid = np.mean(building['points'], axis=0)\n","        ax.text(centroid[0], centroid[1], str(building['height']), color='r', fontsize=12, ha='center')\n","\n","    # Avoid duplicate labels in the legend\n","    handles, labels = plt.gca().get_legend_handles_labels()\n","    by_label = dict(zip(labels, handles))\n","    ax.legend(by_label.values(), by_label.keys())\n","\n","    # Show the plot\n","    plt.show()\n","\n","def read_buildings_from_json(file_path):\n","    \"\"\"\n","    Read building data from a JSON file.\n","\n","    :param file_path: Path to the JSON file\n","    :return: List of buildings with their points and heights\n","    \"\"\"\n","    buildings = []\n","    with open(file_path) as json_file:\n","        data = json.load(json_file)\n","        for shape in data['shapes']:\n","            building = {\n","                'points': shape['points'],\n","                'height': shape['group_id']\n","            }\n","            buildings.append(building)\n","    return buildings\n","\n","dataset_dir = DATA_PATH + 'validation'\n","for filepath in os.listdir(os.path.join(dataset_dir, 'images')):\n","    current_file = filepath.split('.')[0]\n","\n","    image_path = dataset_dir + f'/images/{current_file}.png'\n","    ground_truth_file = dataset_dir + f'/annotations/{current_file}.json'\n","    prediction_file = dataset_dir + f'/predictions/{current_file}.json'\n","\n","    ground_truth_buildings = read_buildings_from_json(ground_truth_file)\n","    predicted_buildings = read_buildings_from_json(prediction_file)\n","\n","    visualize_buildings(image_path, ground_truth_buildings, predicted_buildings)"]},{"cell_type":"code","execution_count":null,"id":"a52e1e62-626d-48c5-a93f-94c9a2e3510e","metadata":{"id":"a52e1e62-626d-48c5-a93f-94c9a2e3510e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a9048d0b-28bb-4415-afb1-9bacfe4cb079","metadata":{"id":"a9048d0b-28bb-4415-afb1-9bacfe4cb079"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"28b1b713-012c-44a9-8caa-458d277450b9","metadata":{"id":"28b1b713-012c-44a9-8caa-458d277450b9"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}